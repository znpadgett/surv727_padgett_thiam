---
title: "Pre- and Post-Debate Democratic Primary Data: Twitter, Google Trends, and Polls"
subtitle: "Fundamentals of Computing and Data Display, Fall 2019"
author: "Zoe Padgett and Fatou Thiam"
date: "`r Sys.Date()`"
fontsize: 12pt
text-align: left
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: fix_float.tex
    toc: yes
    df_print: kable
references:
- id: GayoAvello2013
  title: A Meta-Analysis of State-of-the-Art Electoral Prediction From Twitter Data
  author:
  - family: Gayo-Avello
    given: D.
  container-title: Organization Studies
  volume: 31
  issue: 6
  page: 211–248
  type: article-journal
  issued:
    year: 2013
- id: Beauchamp2017
  title: Predicting and Interpolating State-Level Polls Using Twitter Textual Data
  author:
  - family: Beauchamp
    given: N.
  container-title: American Journal of Political Science 
  volume: 61
  issue: 2
  type: article-journal
  issued:
    year: 2017
- id: Gaurav2013
  title: Leveraging Candidate Popularity on Twitter to Predict Election Outcome
  author:
  - family: Gaurav
    given: M.
  - family: Srivastava
    given: A.
  - family: Kumar
    given: A.
  - family: Miller
    given: S.
  container-title: Proceedings of the 7th Workshop on Social Network Mining and Analysis
  type: article-journal
  issued:
    year: 2013
- id: Kassraie2017
  title: Election Vote Share Prediction using a Sentiment-based Fusion of Twitter Data with Google Trends and Online Polls
  author:
  - family: Kassraie
    given: P.
  - family: Modirshanechi
    given: A.
  - family: Aghajan
    given: H.
  container-title: Proceedings of the 6th International Conference on Data Science, Technology and Applications
  type: article-journal
  issued:
    year: 2017
- id: Salunkhe2017
  title: Twitter Based Election Prediction and Analysis
  author:
  - family: Salunkhe
    given: P.
  - family: Deshmukh
    given: S.
  container-title: International Research Journal of Engineering and Technology
  volume: 4
  issue: 10
  type: article-journal
  issued:
    year: 2017
- id: Gtrendscite   
  title: "gtrendsR: Perform and Display Google Trends Queries"
  author:
  - family: Massicotte
    given: P.
  - family: Eddelbuettel
    given: D.
  issued:
    year: 2019
  note: R package version 1.4.4.9000
  url: https://github.com/PMassicotte/gtrendsR
- id: shinycite
  title: "shiny: Web Application Framework for R"
  author:
  - family: Chang
    given: W.
  - family: Cheng 
    given: J.
  - family: Allaire
    given: J.
  - family: Xie
    given: Y. 
  - family: McPherson
    given: J.
  issued:
    year: 2019
  note: R package version 1.4.0
  url: https://CRAN.R-project.org/package=shiny
- id: mapcite
  title: "ggmap: Spatial Visualization with ggplot2"
  author:
  - family: Kahle
    given: D.
  - family: Wickham
    given: H.
  container-title: The R Journal
  volume: 5
  issue: 1
  page: 144-161
  type: article-journal
  issued:
    year: 2013
  url: https://journal.r-project.org/archive/2013-1/kahle-wickham.pdf
- id: Gtrendscite   
  title: "gtrendsR: Perform and Display Google Trends Queries"
  author:
  - family: Massicotte
    given: P.
  - family: Eddelbuettel
    given: D.
  issued:
    year: 2019
  note: R package version 1.4.4.9000
  url: https://github.com/PMassicotte/gtrendsR
- id: rtweet
  title: "rtweet: Collecting Twitter Data"
  author:
  - family: Kearney
    given: M.
  issued:
    year: 2019
  note: R package version 0.6.9
  url: https://cran.r-project.org/package=rtweet
- id: tidytext
  title: "tidytext: Text Mining and Analysis Using Tidy Data Principles in R"
  author:
  - family: Silge
    given: J.
  - family: Robinson
    given: D.
  url: "http://dx.doi.org/10.21105/joss.00037"
  issued:
    year: 2016
  publisher: The Open Journal
  note: R package version 0.6.9
  volume: 1
  number: 3
  journal: JOSS
- id: sentiment
  title: "SentimentAnalysis: Dictionary-Based Sentiment Analysis"
  author:
  - family: Feuerriegel
    given: S.
  - family: Proellochs
    given: N.
  url: https://CRAN.R-project.org/package=SentimentAnalysis
  issued:
    year: 2019
  note: R package version 1.3-3
- id: quanteda
  title: "quanteda: An R package for the quantitative analysis of textual data"
  author:
  - family: Benoit
    given: K.
  - family: Watanabe
    given: K.
  - family: Wang
    given: H.
  - family: Nulty
    given: P.
  - family: Obeng
    given: A.
  - family: Müller
    given: S.
  - family: Matsuo
    given: A.
  url: https://quanteda.io
  issued:
    year: 2018
- id: tidyverse
  title: "tidyverse: Easily Install and Load the 'Tidyverse'"
  author:
  - family: Wickman
    given: H.
  url: https://CRAN.R-project.org/package=tidyverse
  issued:
    year: 2017
  note: R package version 1.2.1
---


```{r, echo = FALSE, include=FALSE}
library(knitr)
library(tidyverse)
library(gtrendsR)
library(dplyr)
library(ggplot2)
library(ggmap)
library(readxl)
library(shiny)
library(rtweet)
library(tidytext)
library(stringr)
library(lubridate)
library(quanteda)
library(SentimentAnalysis)
library(GGally)
library(repmis)
library(httr)
library(pander)
library(rsconnect)
```

```{r, message="FALSE", warning=FALSE, results="hide", include=FALSE}
opts_chunk$set(tidy.opts=list(width=60),tidy=TRUE)
```
\newpage
## Introduction

Twitter and Google Trends are becoming increasingly popular tools for social science researchers. They represent an easily accessible source of large amounts of data, which has become advantageous as survey response rates decline and costs rise. Researchers interested in predicting election results have begun looking to Twitter data to replace or supplement traditional election polls, with mixed results [@GayoAvello2013]. 

Recently, there have been studies using sentiment analysis of Twitter data to predict election outcomes in India [@Salunkhe2017], to predict state-level polling results in the U.S. [@Beauchamp2017], and to predict the winners of three presidential elections in Latin America [@Gaurav2013]. @Beauchamp2017 found that Twitter data may be useful in making state-level campaign strategy decisions. Additionally, @Kassraie2017 used Google Trends and Twitter data to predict the 2016 U.S. election outcomes with only 1% error. 

We are interested in whether Twitter data and Google trends data could be used to supplement polling results, by providing real-time information to candidates while they wait for polling data to come in. For example, candidates may be interested in understanding how public opinion has shifted immediately after a debate in order to run a more agile campaign. This project is an exploratory analysis of Twitter and Google Trends data to see if pre- and post-debate polling data during the 2020 U.S. Democratic primary election aligns with these real-time sources. 

## Data

All data used to create the tables, figures, and shiny app in this paper can be found on our Github repository at https://github.com/znpadgett/surv727_padgett_thiam. 

### Twitter

Using the rtweet package [@rtweet] and the search_tweet function, we were able to gather sufficient tweets for our project and seperated in two datasets; pre- and post- debate. The initial dataset contains a little over 1.3 million tweets which was rich enough to proceed with analysis. After removing irrelevant tweets such as tweets containing "Ukraine", we were left with over 1.2 million tweets. This was used to create the pre- and post- debate datasets. The pre-debate dataset has 226,799 tweets and 998,780 tweets for the post-debate dataset. As expected, there was a lot more tweets after the debate than before. We used the  Twitter location field to perform analysis at the state level. However, the location column is an open text and not regulated. We selected severals states such New York, Virginia, New Hampshire, Nevada, Illinois, Iowa, Ohio, California and DC to focus our analysis on. 

Below is our token to access the Twitter API and start collecting tweets. Note that these codes are fake, for security purposes.

```{r, eval=FALSE}
create_token(
  app = "fcdd-course",
  consumer_key = "XXXXXXXXXXXXXXXXXXX",
  consumer_secret = "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX",
  access_token = "XXXXXXXXXXXXXXXXXXX-XXXXXXXXXXXXXXXXXXX",
  access_secret = "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
)
```

#### Quering Tweets

Using the search_tweet function in the rtweet package, we will be quering tweets with the specified keywords below. We limited our tweets pull to November 20th and November 21st. The reasonning behind this is to get a sense on how Twitter users feel pre- and post- debate.  


```{r, eval=FALSE, tidy=TRUE}

dem <- search_tweets("#democrats OR #candidates OR #election2020 OR #BIDEN 
                     OR #sanders OR #warren OR #harris 
                     OR #buttigieg OR #steyer OR #yang OR #booker 
                     OR #klobuchar OR #gabbard   
                     OR @KamalaHarris OR @JoeBiden OR @BernieSanders 
                     OR @ewarren OR @PeteButtigieg 
                     OR @TomSteyer OR @AndrewYang OR @BookerCory 
                     OR @amyklobuchar OR @TulsiGabbard ",  since='2019-11-20', 
                     until='2019-11-21', n= 500000, 
    retryonratelimit = TRUE, verbose = TRUE)
```

#### Data Cleaning

Even with specified keywords, irrelevants tweets made it to the initial dataset mainly with the Ukraine issue at the time of pulling. We removed all tweets that had the word "Ukraine" in order to focus completly on tweets regarding the debate. 

```{r, eval=FALSE}
vars <- c("text", "location", "created_at")
df1 <- dem[vars]
df2 <- dem2[vars]
```
                    
```{r, eval=FALSE}
df1 <- df1 %>%
      mutate( ukraine = (str_detect(df1$text, 
                                    regex("Ukraine", 
                                          ignore_case = TRUE)))) %>%
      filter(ukraine=="FALSE") %>%
      select(-ukraine)

df2 <- df2 %>%
      mutate( ukraine = (str_detect(df2$text, 
                                    regex("Ukraine", 
                                          ignore_case = TRUE)))) %>%
      filter(ukraine=="FALSE") %>%
      select(-ukraine)
```
                    
```{r, eval=FALSE}
tweets <- rbind(df1, df2)
```

Next, we seperate the tweets by candidates in order to do analysis at the candidate level. It's important to note that one tweet can be addressed to multiple candidates. In that case, the tweet will be found in the each of those candidates dataset. The code below exemplifies this step of the cleaning process.

```{r, eval=FALSE, tidy=TRUE}
tweets$BS <-(str_detect(tweets$text, 
                        regex("#Sanders|@BernieSanders", 
                              ignore_case = TRUE)))
tweets$KH <-(str_detect(tweets$text, 
                        regex("#harris |@KamalaHarris",  
                              ignore_case = TRUE)))
tweets$JB <-(str_detect(tweets$text, 
                        regex("#biden |@JoeBiden", 
                              ignore_case = TRUE)))
tweets$EW <-(str_detect(tweets$text, 
                        regex("#warren |@ewarren", 
                              ignore_case = TRUE)))
tweets$PB <-(str_detect(tweets$text, 
                        regex("#buttigieg|@PeteButtigieg", 
                              ignore_case = TRUE)))
tweets$TS <-(str_detect(tweets$text, 
                        regex("#steyer | @TomSteyer", 
                              ignore_case = TRUE)))
tweets$AY <-(str_detect(tweets$text, 
                        regex("#yang| @AndrewYang", 
                              ignore_case = TRUE)))
tweets$BC <-(str_detect(tweets$text, 
                        regex("#booker | @BookerCory", 
                              ignore_case = TRUE)))
tweets$AK <-(str_detect(tweets$text, 
                        regex("#klobuchar | @amyklobuchar", 
                              ignore_case = TRUE)))
tweets$TG <-(str_detect(tweets$text, 
                        regex("#gabbard |@TulsiGabbard", 
                              ignore_case = TRUE)))
```

```{r, eval=FALSE, include=FALSE}
df1$BS <-(str_detect(df1$text, regex("#Sanders|@BernieSanders", ignore_case = TRUE)))
df1$KH <-(str_detect(df1$text, regex("#harris |@KamalaHarris",  ignore_case = TRUE)))
df1$JB <-(str_detect(df1$text, regex("#biden |@JoeBiden", ignore_case = TRUE)))
df1$EW <-(str_detect(df1$text, regex("#warren |@ewarren", ignore_case = TRUE)))
df1$PB <-(str_detect(df1$text, regex("#buttigieg|@PeteButtigieg", ignore_case = TRUE)))
df1$TS <-(str_detect(df1$text, regex("#steyer | @TomSteyer", ignore_case = TRUE)))
df1$AY <-(str_detect(df1$text, regex("#yang| @AndrewYang", ignore_case = TRUE)))
df1$BC <-(str_detect(df1$text, regex("#booker | @BookerCory", ignore_case = TRUE)))
df1$AK <-(str_detect(df1$text, regex("#klobuchar | @amyklobuchar", ignore_case = TRUE)))
df1$TG <-(str_detect(df1$text, regex("#gabbard |@TulsiGabbard", ignore_case = TRUE)))
```

```{r, eval=FALSE, include=FALSE}
df2$BS <-(str_detect(df2$text, regex("#Sanders|@BernieSanders", ignore_case = TRUE)))
df2$KH <-(str_detect(df2$text, regex("#harris |@KamalaHarris",  ignore_case = TRUE)))
df2$JB <-(str_detect(df2$text, regex("#biden |@JoeBiden", ignore_case = TRUE)))
df2$EW <-(str_detect(df2$text, regex("#warren |@ewarren", ignore_case = TRUE)))
df2$PB <-(str_detect(df2$text, regex("#buttigieg|@PeteButtigieg", ignore_case = TRUE)))
df2$TS <-(str_detect(df2$text, regex("#steyer | @TomSteyer", ignore_case = TRUE)))
df2$AY <-(str_detect(df2$text, regex("#yang| @AndrewYang", ignore_case = TRUE)))
df2$BC <-(str_detect(df2$text, regex("#booker | @BookerCory", ignore_case = TRUE)))
df2$AK <-(str_detect(df2$text, regex("#klobuchar | @amyklobuchar", ignore_case = TRUE)))
df2$TG <-(str_detect(df2$text, regex("#gabbard |@TulsiGabbard", ignore_case = TRUE)))
```

Here we reformat the created_at column as a date & time variable in order to seperate the tweets in two groups : pre- and post- debate.
```{r, eval=FALSE}
tweets <- tweets %>%
  mutate( date= as.POSIXct(created_at, 
  tryFormats = c("%Y-%m-%d %H:%M:%OS")))

df1 <- df1 %>%
    mutate( date= as.POSIXct(created_at, 
    tryFormats = c("%Y-%m-%d %H:%M:%OS")))

df2 <- df2 %>%
    mutate( date= as.POSIXct(created_at, 
    tryFormats = c("%Y-%m-%d %H:%M:%OS")))

```

All the tweets received before 9 p.m. on November 20th were accounted for in the pre-debate dataset and all tweets from 11 p.m. on November 20th to the next day are in the post-debate dataset. Note that tweets during the debate (9 - 11 p.m.) were removed.
```{r, eval=FALSE, tidy=TRUE}
pre_debate <- tweets %>%
              filter(date(date) == "2019-11-20" & hour(date) < 21 )

post_debate <- tweets %>%
              filter(date(date) == "2019-11-20" & hour(date) >= 23 | 
                       date(date) == "2019-11-21"  )


pre_debate <- pre_debate %>% select(-date, -created_at)
post_debate <- post_debate %>% select(-date, -created_at)
```

#### Sentiment Analysis
Sentiment analysis of the tweets will not be performed for all candidates but five selected candidates; Harris, Sanders, Biden, Warren & Buttigieg.

First, we need to arrange the tweets by removing all non-words such as emojis and use the sentiment analysis package [@sentiment] for analysis. Althought the sentiment analysis package uses 5 dictionnairies, we will only look at the results from the GI dictionnary. For the pre-debate tweets sentiment analysis, we used all the tweets from the dataset. However, for the post-debate sentiment analysis we sampled from the dataset due to volume and space issue. The code below exemplifies this process. The sample size for each candidate post-debate dataset is the same as the pre-debate number of tweets for consistency. For instance, the pre-debate dataset for Sanders had 31,603 tweets, the sample size for the post-debate dataset for Sanders was 31,603.     
```{r, eval=FALSE}
bs <- pre_debate %>%
      filter (BS == "TRUE")

usableText=str_replace_all(bs$text,"[^[:graph:]]", " ")  

usableText <- tolower(bs$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_bs = analyzeSentiment(as.character(usableText))

```

```{r, eval=FALSE, include=FALSE}
bs_post <- post_debate %>%
      filter (BS == "TRUE")

n.sample = 31603
bs_sample = bs_post[sample(1:nrow(bs_post), n.sample, replace=FALSE),]

usableText <- tolower(bs_sample$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_bs_post = analyzeSentiment(as.character(usableText))

```

```{r, eval=FALSE, include=FALSE}
kh <- pre_debate %>%
      filter (KH == "TRUE")

usableText <- tolower(kh$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_kh = analyzeSentiment(as.character(usableText))

##

kh_post <- post_debate %>%
      filter (KH == "TRUE")

n.sample = 16362
kh_sample = kh_post[sample(1:nrow(kh_post), n.sample, replace=FALSE),]

usableText <- tolower(kh_sample$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_kh_post = analyzeSentiment(as.character(usableText))

```


```{r, eval=FALSE, include=FALSE}
jb <- pre_debate %>%
      filter (JB == "TRUE")

usableText <- tolower(jb$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_jb = analyzeSentiment(as.character(usableText))

##
jb_post <- post_debate %>%
      filter (JB == "TRUE")

n.sample = 27477
jb_sample = jb_post[sample(1:nrow(jb_post), n.sample, replace=FALSE),]

usableText <- tolower(jb_sample$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_jb_post = analyzeSentiment(as.character(usableText))

```

```{r, eval=FALSE, include=FALSE}
ew <- pre_debate %>%
      filter (EW == "TRUE")

usableText <- tolower(ew$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_ew = analyzeSentiment(as.character(usableText))

##
ew_post <- post_debate %>%
      filter (EW == "TRUE")

n.sample = 18628
ew_sample = ew_post[sample(1:nrow(ew_post), n.sample, replace=FALSE),]

usableText <- tolower(ew_sample$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_ew_post = analyzeSentiment(as.character(usableText))

```

```{r, eval=FALSE, include=FALSE}
pb <- pre_debate %>%
      filter (PB == "TRUE")

usableText <- tolower(pb$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_pb = analyzeSentiment(as.character(usableText))

##

pb_post <- post_debate %>%
      filter (PB == "TRUE")

n.sample = 27242
pb_sample = pb_post[sample(1:nrow(pb_post), n.sample, replace=FALSE),]

usableText <- tolower(pb_sample$text)

usableText<- iconv(usableText, "UTF-8","ASCII",  sub="byte")

sentiments_pb_post = analyzeSentiment(as.character(usableText))
```

```{r, eval=FALSE, tidy=TRUE}
pre_sent_pos <- data.frame("Candidate" = c("Biden", 
                                           "Sanders", 
                                           "Warren", 
                                           "Harris", 
                                           "Buttigieg"), 
 "Positive" =c((sum(sentiments_jb$PositivityGI))/27477,
(sum(sentiments_bs$PositivityGI))/31603,                                                                    (sum(sentiments_ew$PositivityGI))/18628,
(sum(sentiments_kh$PositivityGI))/16362,
(sum(sentiments_pb$PositivityGI))/27242))
```

```{r, eval=FALSE, include=FALSE}
post_sent_pos <- data.frame("Candidate" = c("Biden", "Sanders", "Warren", 
                                            "Harris", "Buttigieg"), 
"Positive" =c((sum(sentiments_jb_post$PositivityGI))/27477,
(sum(sentiments_bs_post$PositivityGI))/31603,                                                             (sum(sentiments_ew_post$PositivityGI))/18628,
(sum(sentiments_kh_post$PositivityGI))/16362,
(sum(sentiments_pb_post$PositivityGI))/27242))
```



### Google Trends
This section describes gathering the Google Trends data using the package gtrendsR [@Gtrendscite]. First, we register our Google API key. Then, we pull data for each candidate from the 2 days preceding and two days following the debate (November 18 through 22). We have to pull the data in two separate blocks, because gtrendsR only allows us to use five search terms at a time. We limit the location of searches to the US. Please note that the key here is not a real API key, for security purposes.

```{r, eval=FALSE, tidy=TRUE}
register_google(key = "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX")
res1 <- gtrends(c("Joe Biden", "Bernie Sanders", 
                  "Elizabeth Warren", "Kamala Harris", 
                  "Pete Buttigieg"), geo = "US", 
time = "2019-11-18 2019-11-22", low_search_volume = T)

res2 <- gtrends(c("Tom Steyer", "Andrew Yang", "Cory Booker", 
                  "Amy Klobuchar", "Tulsi Gabbard"), geo = "US", 
time = "2019-11-18 2019-11-22", low_search_volume = T)
```

#### Geocoding

Next, we compile and clean the Google Trends location data and prepare it for geocoding.

```{r, , eval=FALSE}
interest_by_location1 <- as_tibble(res1$interest_by_dma)
interest_by_location2 <- as_tibble(res2$interest_by_dma)
interest_by_location <- rbind(interest_by_location1, interest_by_location2)

locations_df <- as.data.frame(interest_by_location)
locations_df$location <- as.character(locations_df$location)
```

Then, we geocode the Google trends data.
```{r, eval=FALSE}
gc_locations <- as_tibble(mutate_geocode(locations_df, location))
```

#### Data Cleaning

Next, we categorize the Google Trends data into pre-debate and post-debate data, based on the date.
```{r, eval=FALSE}
interest_over_time1 <- as_tibble(res1$interest_over_time)
interest_over_time2 <- as_tibble(res2$interest_over_time)
interest_over_time <- rbind(interest_over_time1, interest_over_time2)

interest_over_time_pre <-
  interest_over_time %>%
  filter(date < "2019-11-19") %>%
  mutate(Pre_post="Pre-debate")

interest_over_time_post <-
  interest_over_time %>%
  filter(date > "2019-11-20") %>%
  mutate(Pre_post="Post-debate")

interest_over_time_all <- rbind(interest_over_time_pre, 
                              interest_over_time_post)
```

### Polls

Polling data was collected from RealClearPolitics.com, which aggregates weekly polls. We created a dataset using the RealClearPolitics average before and after the November 20 debate. Because the website changes often, and we only needed a small snapshot of the data, it was more efficient to clean the data in Excel and import to R than to use web scraping.

```{r, tidy=TRUE}
github_link <- "https://github.com/znpadgett/surv727_padgett_thiam/raw/master/Data/Project%20polling%20data.xlsx"
temp_file <- tempfile(fileext = ".xlsx")
req <- GET(github_link, 
           write_disk(path = temp_file))
polling_data <- readxl::read_excel(temp_file)
```

## Results

### Data Exploration

#### Twitter

Table 1 shows the number of mentions by candidate pre- and post- debate and Table 2 (CA only) shows similar results adding location as a factor. In both tables, we see that there were lot more tweets after the debate. This was anticipated with the debate being a headline the next day. This was also the reason why we decided to focus on pre- and post- debate analysis and not focus on the number of tweets. Sentiment analysis was performed using the GI dictionnaire in the sentiment analysis package [@sentiment].Each tweet received a positive, neutral and/ or negative score. For this project, we summed the positive score of all tweets and divided by the number of tweets in each dataset. This gave us the average tweet positivity by candidate shown in Table 3. Candidate tweet positivity scrore pre- debate are very close with 15% for Sanders being the highest. We notice a slight increase for all candidates with Sanders in the lead still at 16%.

```{r, include=FALSE}
#USE THIS CHUNK TO BRING IN table1, table2 and table3
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/table1.RData?raw=true")
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/table2.RData?raw=true")
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/table3.RData?raw=true")
```

```{r}
panderOptions('table.caption.prefix', 'Table 1: ')
pander(table1 ,caption = "Count of tweets that mentionned 
       candidates pre- and post- debate.")
```

```{r}
panderOptions('table.caption.prefix', 'Table 2: ')
pander(table2 ,caption = "Count of tweets that mentionned 
       candidates in California pre- and post- debate.")
```

```{r}
panderOptions('table.caption.prefix', 'Table 3: ')
pander(table3 ,caption = "Sentiment Analysis average positivity 
       score pre- and post- debate by candidate.")
```

##### Create functions
Create a function to tabulate the count and proportion of tweets by candidates. 

```{r, eval=FALSE}
type_var  <- unlist(map(pre_debate, class))

freq_tab <- function(x) {
tab <- cbind(Count = table(x, useNA = "ifany"),
Prop = round(prop.table(table(x, useNA = "ifany")),
2))
tab <- as.data.frame(tab) %>%
tbl_df() %>%
mutate(Cat = row.names(tab)) %>%
select(Cat, Count, Prop)
}


```

```{r, eval=FALSE}
props1 <- map(pre_debate[, type_var == "logical"], freq_tab)
props2 <- map(post_debate[, type_var == "logical"], freq_tab)


vars <- unlist(map(props1, nrow))

props_tab1 <- reduce(props1, rbind)
props_tab2 <- reduce(props2, rbind)


```


```{r, eval=FALSE}
props_tab1 <- props_tab1 %>%
mutate(Variable = rep(names(vars), vars),
       Candidate = ifelse(Variable == "BS", "Sanders",
                   ifelse(Variable == "KH", "Harris",
                   ifelse(Variable == "JB", "Biden",
                   ifelse(Variable == "EW", "Warren",
                   ifelse(Variable == "PB", "Buttigieg",
                   ifelse(Variable == "TS", "Steyer",         
                   ifelse(Variable == "AY", "Yang", 
                   ifelse(Variable == "BC", "Booker",
                   ifelse(Variable == "AK", "Klobuchar",
                   ifelse(Variable == "TG", "Gabbard", NA)))))))))))

props_tab2 <- props_tab2 %>%
mutate(Variable = rep(names(vars), vars), 
        Candidate = ifelse(Variable == "BS", "Sanders",
                   ifelse(Variable == "KH", "Harris",
                   ifelse(Variable == "JB", "Biden",
                   ifelse(Variable == "EW", "Warren",
                   ifelse(Variable == "PB", "Buttigieg",
                   ifelse(Variable == "TS", "Steyer",         
                   ifelse(Variable == "AY", "Yang", 
                   ifelse(Variable == "BC", "Booker",
                   ifelse(Variable == "AK", "Klobuchar",
                   ifelse(Variable == "TG", "Gabbard", NA)))))))))))
```


##### Graphing
A visual of the proportion of tweets pre- and post- debate


```{r, include=FALSE}
#USE THIS CHUNK TO BRING IN props_tab1, props_tab2, loc_pre_all and loc_post_all 
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/props_tab1.RData?raw=true")
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/props_tab2.RData?raw=true")
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/loc_pre_all.RData?raw=true")
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/loc_post_all.RData?raw=true")

```

###### Pre-debate number of tweets 

```{r, fig.cap="Pre-debate Mentions in Tweets, by Candidate"}
props_tab1 %>%
  filter(Cat == "TRUE") %>%
  ggplot() +
  geom_col(mapping = aes(x = reorder(Candidate, -Count), 
  y=Count, fill = Candidate)) +
    labs(x = "Democratic Party Candidates", 
       y = "Number of Tweets", 
           caption = "Source: Twitter") +
theme(axis.text.x=element_text(angle=90,hjust=1)) 
```
Figure 1 shows the number of tweets that mentioned each candidate before the debate. We noticed that Sanders, Biden and Buttigieg are in the lead with over 25,000 tweets mentions. 


###### Post-debate number of tweets 
```{r, fig.cap="Post-debate Mentions in Tweets, by Candidate"}
props_tab2 %>%
  filter(Cat == "TRUE") %>%
  ggplot() +
  geom_col(mapping = aes(x = reorder(Candidate, -Count),
  y=Count, fill = Candidate)) +
    labs(x = "Democratic Party Candidates", 
       y = "Number of Tweets", 
       title = "Post Debate candidates mentions in Tweets", 
            caption = "Source: Twitter") +
theme(axis.text.x=element_text(angle=90,hjust=1)) 
```

Figure 2 shows the post- debate tweets mentions by candidate. As expected, lot more tweets mentions occured after the debate, about 5 times more than pre- debate. Here we noticed that the ranking change with Harris and Yang in the lead along with Sanders and tweets mentions close to 150,000.       

###### Tweets location pre-debate 
```{r, fig.cap="Pre-debate Mentions in Tweets, by Candidate & location"}

 loc_pre_all %>%
  mutate(Location = loc) %>%
  group_by(Candidate, Location) %>%
  summarise(total = n()) %>%
  ggplot() +
  geom_col(mapping = aes(x = reorder(Candidate, -total), 
  y=total, fill = Location)) +
    labs(x = "Democratic Party Canditates", 
       y = "Number of Tweets", 
       title = "Pre Debate candidates mentions in Tweets by location", 
             caption = "Source: Twitter") +
           theme(axis.text.x=element_text(angle=90,hjust=1))      
```
Figure 3 shows the number of tweets mentions by candidate by location pre- debate. Here we notice that Buttigieg, Sanders and Yang get the most tweets mentions and mainly coming from California and New York for all 3 candidates. These results are not surprising with California and New York population presence in Twitter. 


###### Tweets location post-debate 
```{r, fig.cap="Post-debate Mentions in Tweets, by Candidate & location"}

 loc_post_all %>%
  mutate(Location = loc) %>%
  group_by(Candidate, Location) %>%
  summarise(total = n()) %>%
  ggplot() +
  geom_col(mapping = aes(x = reorder(Candidate, -total), 
  y=total, fill = Location)) +
    labs(x = "Democratic Party Canditates", 
       y = "Number of Tweets", 
       title = "Post Debate candidates mentions in Tweets by location", 
              caption = "Source: Twitter") +
theme(axis.text.x=element_text(angle=90,hjust=1)) 
```
Figure 4 is the post- debate tweets mentions by candidate by location. Just like in Figure 3 (pre-debate analysis) California and New York had the most users tweeting about the candidates.Harris, Yang and Sanders are mostly mentionned in tweets by users. 

#### Google Trends

To explore the Google Trends data, we examined the location and density of searches for each candidate. We created a map showing our results [@mapcite]. Because it was difficult to see the results for each candidate overlaid on one map, we added a facet wrap to show each individual candidate.
```{r, include=FALSE}
#USE THIS CHUNK TO BRING IN gc_locations
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/gc_locations.RData?raw=true")
```

```{r, message=FALSE, warning=FALSE, results="hide", fig.show="hide"}
#get map
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
us_map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(us_map) 
```

```{r, message=FALSE, warning=FALSE, fig.height=10, fig.width=12, fig.cap="Map of Google Trends Hits, by Candidate"}
#clean data for mapping
trends_map <-
  gc_locations %>%
  group_by(keyword, location) %>%
  mutate("Hits"=sum(hits), Candidate=keyword)

#generate map
ggmap(us_map) + 
  geom_point(data = trends_map, aes(x = lon, y = lat, size=Hits, color=Candidate), 
               alpha = 0.2) +
  theme(axis.line=element_blank(),axis.text.x=element_blank(),
            axis.text.y=element_blank(),axis.ticks=element_blank(),
            axis.title.x=element_blank(),
            axis.title.y=element_blank()) +
  facet_wrap("Candidate", shrink=FALSE)
```

These maps show that candidates have different distributions and density of searches. Searches are more common near the coasts, and less common in the middle of the country.

We also explored the number of hits pre- and post- debate for each candidate.
```{r, include=FALSE}
#USE THIS CHUNK TO BRING IN interest_over_time_all
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/interest_over_time_all.RData?raw=true")
```

```{r, tidy=TRUE, fig.cap="Pre- and Post-debate Google Trends Data, by Candidate"}
interest_over_time_all$Pre_post <- factor(interest_over_time_all$Pre_post, 
                                          levels = c("Pre-debate", "Post-debate"))

interest_over_time_all %>%
  group_by(keyword, Pre_post) %>%
  summarise(avg_hits=mean(hits)) %>%
  ggplot() +
  geom_col(mapping = aes(x=reorder(keyword, -avg_hits), 
             y=avg_hits, fill=Pre_post), color="black", 
           position="dodge") +
  xlab("Candidate") + ylab("Hits") +
  scale_fill_discrete(name = "Timeframe") +
  theme(axis.text.x = element_text(angle=35))
  
```

All candidates had higher search counts after the debate than before. This makes sense, because after a debate there is an increase in the number of news stories about candidates, which may lead to increased interest and thus, increased search activity. Additionally, users may be searching Google to learn about a candidate's debate performance if they did not watch the debate live.

#### Polling Data

For the polling data, we looked at the pre- and post-debate polling numbers for each candidate.
```{r, tidy=TRUE, fig.cap="Pre- and Post-debate Polling Data, by Candidate"}
polling_data$Pre_post <- factor(polling_data$Pre_post, 
levels = c("Pre-debate", "Post-debate"))

polling_data %>%
  group_by(Candidate, Pre_post) %>%
  filter(Candidate!="Bennet", Candidate!="Bloomberg") %>%
  ggplot() +
    geom_col(mapping = aes(x=reorder(Candidate, -Percentage)
    , y=Percentage, fill=Pre_post), color="black", 
    position="dodge") +
  xlab("Candidate") + ylab("Percentage") +
  scale_fill_discrete(name = "Timeframe") +
  theme(axis.text.x = element_text(angle=35))
```

### Analysis

We created a Shiny app that allows us to compare the polling, Google Trends, and Twitter sentiment data [@shinycite]. 

First, we cleaned up and combined the three data sources for use in the Shiny app.

```{r, include=FALSE}
#USE THIS CHUNK TO BRING IN pre_sent_pos and post_sent_pos
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/post_sent_pos.RData?raw=true")
source_data("https://github.com/znpadgett/surv727_padgett_thiam/blob/master/Data/pre_sent_pos.RData?raw=true")
```

```{r, tidy=TRUE, warning=FALSE, message=FALSE}
#clean data
gtrends <-
  interest_over_time_all %>%
  mutate(Candidate=keyword, Data="GTrends") %>%
  filter(Candidate %in% c("Joe Biden", "Bernie Sanders", 
                          "Elizabeth Warren", "Kamala Harris", 
                          "Pete Buttigieg")) %>%
  group_by(Candidate, Pre_post, Data) %>%
  arrange(Candidate, Pre_post) %>%
  summarise(Percentage=mean(hits))

poll <-
  polling_data %>%
  select(Candidate, Pre_post, Percentage) %>%
  filter(Candidate %in% c("Joe Biden", "Bernie Sanders", 
                          "Elizabeth Warren", "Kamala Harris", 
                          "Pete Buttigieg")) %>%
  mutate(Data="Polling") %>%
  arrange(Candidate, Pre_post) %>%
  group_by(Candidate, Pre_post, Data)

twitter_data <- data.frame("Candidate" = c("Joe Biden", "Bernie Sanders", 
                                           "Elizabeth Warren", "Kamala Harris", 
                                           "Pete Buttigieg", "Joe Biden", 
                                           "Bernie Sanders", "Elizabeth Warren", 
                                           "Kamala Harris", "Pete Buttigieg"),                            
                           "Pre_post" =c("Pre-debate","Pre-debate", "Pre-debate",
                           "Pre-debate","Pre-debate","Post-debate","Post-debate",
                           "Post-debate","Post-debate","Post-debate"),
                   "Data" = c("Twitter", "Twitter","Twitter","Twitter","Twitter",
                              "Twitter","Twitter","Twitter","Twitter","Twitter"), 
 "Percentage"=c(pre_sent_pos$Positive[1],pre_sent_pos$Positive[2],
  pre_sent_pos$Positive[3],pre_sent_pos$Positive[4],
  pre_sent_pos$Positive[5],post_sent_pos$Positive[1],
  post_sent_pos$Positive[2],post_sent_pos$Positive[3],
  post_sent_pos$Positive[4],post_sent_pos$Positive[5]))

twitter <- as_tibble(twitter_data)
twitter <-
  twitter %>%
  group_by(Candidate, Pre_post, Data) %>%
  arrange(Candidate, desc(Pre_post)) %>%
  mutate(Percentage=Percentage*100)

all_data <- rbind(poll, gtrends, twitter)

all_data$Pre_post <- factor(all_data$Pre_post, levels = c("Pre-debate", 
                                                          "Post-debate"))

```

Then, we created a shiny app, which can be viewed at https://znpadgett.shinyapps.io/surv727app/:
```{r, eval=FALSE, tidy=TRUE}
# Define UI

ui <- fluidPage(
  
  # Application title
  titlePanel("2020 Democratic Primary Candidate Data"),
  
  # Sidebar with a dropdown
  sidebarLayout(
    sidebarPanel(
      selectInput(inputId = "Candidate",                   
                  label = "Candidate",                  
                  choices = c("Joe Biden", "Pete Buttigieg", "Kamala Harris", 
                              "Bernie Sanders", "Elizabeth Warren"),                   
                  selected = "Joe Biden"),
      selectInput(inputId = "Data",
                  label = "Data Type",
                  choices = c("Polling", "GTrends", "Twitter"),
                  selected = "Polling")
    ),
    
    # Show plot
    mainPanel(
      plotOutput(outputId = "graph")      
    )
  )
)

# Define server logic
server <- function(input, output) {
  
  output$graph <- renderPlot({
    all_data %>%
      filter(Candidate == input$Candidate, Data == input$Data) %>%
      ggplot() +
      geom_col(mapping = aes(x=Pre_post, y=Percentage, 
      fill=input$Candidate)) +
      ylim(0,100) +
      xlab("Timeframe") + ylab("Percentage") +
      theme(legend.position = "none")
  })
}

# Run the application 
shinyApp(ui = ui, server = server)
```

Finally, we examined the relationships between the polling data and the Twitter and Google Trends data post-debate, as well as the relationships between pre- and post-debate changes across data sources. We looked at these results for the 5 most popular candidates.

```{r, tidy=TRUE, fig.cap="Comparison of Post-debate Twitter and Polling Data"}
graphing_data <- cbind(twitter, poll, gtrends)
graphing_data %>%
  group_by(Pre_post, Candidate) %>%
  filter(Pre_post=="Post-debate") %>%
  ggplot() +
  geom_point(mapping = aes(x=Percentage, y=Percentage1, 
                           color=Candidate), size=4) +
  xlim(0,20) +
  ylim(0,30) +
  labs(x="Twitter Sentiment", 
       y="Polling Data")
```

Figure 5 shows that there is no clear relationship between the post-debate twitter sentiment and the polling data. All candidates have similar sentiment scores, regardless of polling percentage.

```{r, tidy=TRUE, fig.cap="Comparison of Post-debate Google Trends and Polling Data"}
graphing_data  %>%
  group_by(Pre_post, Candidate) %>%
  filter(Pre_post=="Post-debate") %>%
  ggplot() +
  geom_point(mapping = aes(x=Percentage2, y=Percentage1, 
                           color=Candidate), size=4) +
  xlim(0,100) +
  ylim(0,30) +
  labs(x="Google Trends Data", 
       y="Polling Data")
```

In Figure 6, we can see a very slight relationship between the post-debate Google Trends data and polling data, in that candidates polling higher generally had higher Google trends hit rates.

```{r, tidy=TRUE, fig.cap="Comparison of Changes in Twitter and Polling Data"}
pre <-
graphing_data  %>%
  select(Pre_post, Candidate, Percentage, Percentage1, Percentage2) %>%
  group_by(Pre_post, Candidate, Data) %>%
  filter(Pre_post=="Pre-debate") %>%
  mutate(Pre_twitter=Percentage, Pre_polling=Percentage1, 
         Pre_gtrends=Percentage2)

post <-
  graphing_data  %>%
  select(Pre_post, Candidate, Percentage, Percentage1, Percentage2) %>%
  group_by(Pre_post, Candidate, Data) %>%
  filter(Pre_post=="Post-debate") %>%
  mutate(Post_twitter=Percentage, Post_polling=Percentage1, 
         Post_gtrends=Percentage2)

change_data <- cbind(pre, post)

change_data %>%
  group_by(Pre_post, Candidate) %>%
  mutate(change_twitter = ((Post_twitter - Pre_twitter) / 
                             Pre_twitter) * 100, 
         change_polling = ((Post_polling - Pre_polling) / 
                             Pre_polling) * 100, 
         change_gtrends = ((Post_gtrends - Pre_gtrends) / 
                             Pre_gtrends) * 100) %>%
  ggplot() +
  geom_point(mapping = aes(x=change_twitter, y=change_polling, 
                           color=Candidate), size=4) +
  labs(x="Percent Change in Twitter Sentiment", 
       y="Percent Change in Polling Data")
  
```

Figure 7 shows the percent change in Twitter sentiment and percent change in vote share between the two time periods (pre- and post-debate). There is no clear relationship between the change in vote share and the change in Twitter sentiment.

```{r, tidy=TRUE, fig.cap="Comparison of Changes in Google Trends and Polling Data"}
change_data %>%
  group_by(Pre_post, Candidate) %>%
  mutate(change_twitter = ((Post_twitter - Pre_twitter) / 
                             Pre_twitter) * 100, 
         change_polling = ((Post_polling - Pre_polling) / 
                             Pre_polling) * 100, 
         change_gtrends = ((Post_gtrends - Pre_gtrends) / 
                             Pre_gtrends) * 100) %>%
  ggplot() +
  geom_point(mapping = aes(x=change_gtrends, y=change_polling, 
                           color=Candidate), size=4) +
  labs(x="Percent Change in Google Trends Data", 
       y="Percent Change in Polling Data")
```

Figure 8 shows the percent change in Google Trends hit rate and percent change in vote share between the two time periods. Again, there is no clear relationship between the change in the two data sources.

In conclusion, when looking at the pre- and post-debate data from each source side-by-side, we can see that, while candidates who are polling higher have higher numbers of tweets and Google searches (for the most part), there is no clear relationship between the post-debate changes in polling numbers and the post-debate changes in Twitter and Google Trends data. Regardless of polling numbers, all candidates had higher Twitter positivity ratings and higher numbers of Google searches post-debate than pre-debate. 

## Discussion

Our results show that neither Twitter nor Google Trends data align with pre- and post-debate changes in polling numbers There were no discernable patterns that relate the found data to the polling data. There may be many reasons why the found data did not align with the polling data. For one, the found data are not representative of U.S. voters, only Twitter users or Google searches, and the lack of availability of demographic data does not allow for weighting adjustments. Variable-to-variable comparison between two data sources may not be realistic. For example, a large number of searches and higher positivity of tweets may not actually mean that more people will vote for a candidate.

Additionally, there are many practical difficulties in using the found data, for example that the location field in the Twitter data corresponds to self-reported location, an open-ended field. Many users give incorrect or fake locations.

Overall, we don't think that this data should be used in place of survey data when it comes to election polling. However, this data could still be useful for candidates in understanding how social media users percieve them before and after a debate, or in understanding their search popularity. It is important to recognize that these measures are not an accurate proxy for voter opinion, but they could still be useful in their own right. Campaigns would also need to recognize that the target population of any inferences may on these data is not U.S. voters, or even all those living in the U.S., but is actually the population of tweets (for the Twitter data) or Google searches (for the Google Trends data). When these considerations are taken into account, we still think that this data could be useful for campaign strategy.

It would be advantageous to survey methodologists to be able to use sources such as Twitter and Google Trends to replace survey data. However, we need to acknowledge the limitations preventing us from doing so. We all will agree that Twitter users do not adequately represent the population consequently introducing coverage error. Validity and measurement error just to name a few limitations we encountered with Twitter data. In lieu of replacing survey data, Twitter data can and should be use as a supplemental data. It is also important to note that we collected data for a short period of time. We believed that Twitter data can be much more useful if we had a longer timeframe. With that we would be able to perform more in depht analysis with time a key variable or even fit models. For instance, the next democratic debate is scheduled for December 19th, it would be intersting to see how the sentiment differ from the November 21st debate. On that point, candidates could use Twitter data for many other purposes such as percpetion in the Twitter world or change over time in sentiment but definitely not for election outcomes.

## References


